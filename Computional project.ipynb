{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import coint\n",
    "from quantopian.pipeline.filters import Q500US\n",
    "from quantopian.pipeline.factors import AverageDollarVolume\n",
    "from quantopian.pipeline.data import Fundamentals\n",
    "from quantopian.pipeline.classifiers.fundamentals import Sector\n",
    "from quantopian.pipeline import Pipeline\n",
    "from quantopian.research import run_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pairs Trading Strategy\n",
    "## Shuyu Hao, Yumeng Zhang, Zheng Li, Xiangyuan Xie\n",
    "### 2020-6-22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General Defination: \n",
    "Pairs trading is to find stock pairs that are highly correlated and to trade the stock price spreads: short the spread when the spread is above a certain bound; long the spread when the spread is below a certain bound.\n",
    "#### Basic Assumption: \n",
    "Highly correlated stock pairs' price spreads will fluctuate in a certain range with a certain mean.\n",
    "#### Research Process:\n",
    "Find and test those stock pairs which accord with our general defination and have high cointegration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 Building Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting data\n",
    "Choose the ticker symbols of top 100 Q500US stocks which have the largest dollar volume and make pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dollar_volume = AverageDollarVolume(window_length =1)\n",
    "high_dollar_volume = dollar_volume.top(100, mask = Q500US())\n",
    "my_symbol = Fundamentals.symbol.latest \n",
    "sector = Fundamentals.morningstar_sector_code.latest\n",
    "my_pipe = Pipeline(\n",
    "        columns={'my_symbol' : my_symbol, \n",
    "                 'sector': sector},\n",
    "        screen = high_dollar_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_pipeline(my_pipe, '2014-01-01', '2014-01-01')\n",
    "results = results.xs('2014-01-02')\n",
    "symbol_list = results.my_symbol.tolist()\n",
    "symbol_list.remove('GOOGL')\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 Get cointegrated pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cointegration simply tests if two stocks' price spreads fluctuate with a certain mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to get conintegrated pairs\n",
    "def find_cointegrated_pairs(data, df):\n",
    "    n = data.shape[1]\n",
    "    score_matrix = np.zeros((n, n))\n",
    "    pvalue_matrix = np.ones((n, n))\n",
    "    correlation_matrix = np.ones((n,n))\n",
    "    keys = data.keys()\n",
    "    pairs = []\n",
    "    pairs1 = []\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            S1 = data[keys[i]]\n",
    "            S2 = data[keys[j]]\n",
    "            sec1 = df['sector'][i]\n",
    "            sec2 = df['sector'][j]\n",
    "            result = coint(S1, S2)\n",
    "            score = result[0]\n",
    "            pvalue = result[1]\n",
    "            score_matrix[i, j] = score\n",
    "            pvalue_matrix[i, j] = pvalue\n",
    "            if pvalue < 0.01 and sec1 == sec2: \n",
    "                pairs.append((keys[i]))\n",
    "                pairs.append(keys[j])\n",
    "                pairs1.append((keys[i], keys[j]))\n",
    "                print('(' + 'symbol' + '(' + \"'\"+ keys[i] +\"'\" + ')' + ',' + 'symbol' + '(' + \"'\" + keys[j] +\"'\"+ ')'+ ')' + ',')\n",
    "    return score_matrix, pvalue_matrix, pairs, pairs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pricing dataframe\n",
    "prices = get_pricing(symbol_list, fields=['price']\n",
    "                               , start_date='2014-01-01', end_date='2015-01-01')['price']\n",
    "prices.columns = map(lambda x: x.symbol, prices.columns)\n",
    "prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print results\n",
    "scores, pvalues, pairs, pairs1 = find_cointegrated_pairs(prices, results)\n",
    "print pairs\n",
    "print('we found ' + str(len(pairs1))+ ' pairs in the dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 Visualize Cointegration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pvalues\n",
    "for i in pairs1:\n",
    "    S1 = prices[i[0]]\n",
    "    S2 = prices[i[1]]\n",
    "    score, pvalue, _ = coint(S1, S2)\n",
    "    print pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S1 = prices['DAL']\n",
    "S2 = prices['MMM']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression \n",
    "Regression tells us how the price change of one stock is related to that of another stock. Theoratically, we want to hedge the beta between two stocks and only concentrate on the pure alpha to reduce dollar exposure, but sometimes dollar exposure can bring profits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regress S2 on S1 and get the beta, which is the hedge ratio\n",
    "S1 = sm.add_constant(S1)\n",
    "results = sm.OLS(S2, S1).fit()\n",
    "S1 = S1['DAL']\n",
    "b = results.params['DAL']\n",
    "S2.plot(legend = True)\n",
    "S1.plot(legend = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the price pure spread to see if it behaves like a random noise\n",
    "spread = S2 - b * S1\n",
    "spread.plot()\n",
    "plt.axhline(spread.mean(), color='black')\n",
    "plt.legend(['Spread'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Z-score\n",
    "Usually we want to standardize a series to find specific bound or signals for us to trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ploting Z-score\n",
    "def zscore(series):\n",
    "    return (series - series.mean()) / np.std(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zscore(spread).plot()\n",
    "plt.axhline(zscore(spread).mean(), color='black')\n",
    "plt.axhline(1.0, color='red', linestyle='--')\n",
    "plt.axhline(-1.0, color='green', linestyle='--')\n",
    "plt.legend(['Spread z-score', 'Mean', '+1', '-1']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 Using the most recent data \n",
    "Even the spread we calculated behaves like a random alpha, the volatility of the spread will change. Therefore,we roll the most recent data to:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run regression\n",
    "get rolling beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Rolling Beta\n",
    "rolling_beta = pd.ols(y=S2, x=S1, window_type='rolling', window=30)\n",
    "spread = S2 - rolling_beta.beta['x'] * S1\n",
    "spread.name = 'spread'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Z-scores \n",
    "get rolling z-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 1 day moving average of the price spread\n",
    "mavg1 = pd.rolling_mean(spread, window=1)\n",
    "mavg1.name = 'spread 1d mavg'\n",
    "\n",
    "# Get the 30 day moving average of the price spread\n",
    "mavg30 = pd.rolling_mean(spread, window=30)\n",
    "mavg30.name = 'spread 30d mavg'\n",
    "\n",
    "std30 = pd.rolling_std(spread, window=30)\n",
    "std30.name = 'std 30d'\n",
    "#Calculate rolling zscore\n",
    "z_30_1 = (mavg1 - mavg30)/std30\n",
    "z_30_1.name = 'z-score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mavg1.index, mavg1.values)\n",
    "plt.plot(mavg30.index, mavg30.values)\n",
    "\n",
    "plt.legend(['1-Day Spread MAVG', '30-Day Spread MAVG'])\n",
    "plt.ylabel('Spread');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### for this pair of stocks, a bound of 1 may not be the best choice as the trading signal, 2 would be better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_30_1.plot()\n",
    "plt.axhline(0, color='black')\n",
    "plt.axhline(1.0, color='red', linestyle='--');\n",
    "plt.axhline(2.0, color='green', linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import quantopian.optimize as opt\n",
    "import quantopian.algorithm as algo\n",
    "import statsmodels.api as sm\n",
    "\n",
    " \n",
    "MAX_GROSS_EXPOSURE = 1.0 # Set exposure constraint constant value for optimizer\n",
    "    \n",
    "def initialize(context):\n",
    "    \"\"\"\n",
    "    Called once at the start of the algorithm.\n",
    "    \"\"\"\n",
    "    schedule_function(check_pair_status, date_rules.every_day(), time_rules.market_close(minutes=30))\n",
    "    \n",
    "  \n",
    "\n",
    "    context.stocks = [(symbol('MMM'),symbol('DAL')),\n",
    "                      (symbol('DDD'),symbol('P')),\n",
    "                      (symbol('UPS'),symbol('DAL'))]\n",
    "\n",
    "    # Our threshold for trading on the z-score\n",
    "    context.entry_threshold = 2\n",
    "    context.exit_threshold = 0.05\n",
    "    \n",
    "    # Create a variable to store our target weights\n",
    "    context.target_weights = pd.Series(index=context.stocks, data=0.0)\n",
    "    \n",
    "    # Moving average lengths\n",
    "    context.long_ma_length = 30\n",
    "    context.short_ma_length = 1\n",
    "    \n",
    "    # Flags to tell us if we're currently in a trade\n",
    "    context.currently_long_the_spread = False\n",
    "    context.currently_short_the_spread = False\n",
    "\n",
    "\n",
    "def check_pair_status(context, data):\n",
    "    \n",
    "    for pair in context.stocks:\n",
    "    # For notational convenience\n",
    "        s1 = pair[0]\n",
    "        s2 = pair[1]\n",
    "    # Get pricing history\n",
    "        prices = data.history([s1, s2], \"price\", context.long_ma_length, '1d')\n",
    "        \n",
    "        #try:\n",
    "            #hedge_r = hedge_ratio(prices[s1], prices[s2], add_const=True)      \n",
    "        #except ValueError as e:\n",
    "            #log.debug(e)\n",
    "            #return\n",
    "    \n",
    "\n",
    "        short_prices = prices.iloc[-context.short_ma_length:]\n",
    "    \n",
    "    # Get the long mavg\n",
    "        long_ma = np.mean(prices[s1] - prices[s2])\n",
    "                          #hedge_r * prices[s2])\n",
    "    # Get the std of the long window\n",
    "        long_std = np.std(prices[s1] - prices[s2])\n",
    "                          #hedge_r * prices[s2])\n",
    "        \n",
    "    \n",
    "    \n",
    "    # Get the short mavg\n",
    "        short_ma = np.mean(short_prices[s1] - short_prices[s2])\n",
    "                           #hedge_r * short_prices[s2])\n",
    "    \n",
    "    # Compute z-score\n",
    "        if long_std > 0:\n",
    "            zscore = (short_ma - long_ma)/long_std\n",
    "    \n",
    "        # Our two entry cases\n",
    "            if zscore > context.entry_threshold and \\\n",
    "                not context.currently_short_the_spread:\n",
    "                context.target_weights[s1] = -1/(2*len(context.stocks)) # short top\n",
    "                context.target_weights[s2] = 1/(2*len(context.stocks))#*hedge_r # long bottom\n",
    "                context.currently_short_the_spread = True\n",
    "                context.currently_long_the_spread = False\n",
    "                allocate(context, data)\n",
    "                return\n",
    "            \n",
    "            elif zscore < -context.entry_threshold and \\\n",
    "                not context.currently_long_the_spread:\n",
    "                context.target_weights[s1] = 1/(2*len(context.stocks)) \n",
    "                context.target_weights[s2] = -1/(2*len(context.stocks))#*hedge_r\n",
    "                context.currently_short_the_spread = False\n",
    "                context.currently_long_the_spread = True\n",
    "                allocate(context, data)\n",
    "                return\n",
    "            \n",
    "        # Our exit case\n",
    "            elif abs(zscore) < context.exit_threshold:\n",
    "                context.target_weights[s1] = 0 # close out\n",
    "                context.target_weights[s2] = 0 # close out\n",
    "                context.currently_short_the_spread = False\n",
    "                context.currently_long_the_spread = False\n",
    "                allocate(context, data)\n",
    "                return\n",
    "                \n",
    "            record('zscore', zscore)\n",
    "    \n",
    "    # Call the tra\n",
    "    \n",
    "#def hedge_ratio(Y, X, add_const=True):\n",
    "    #if add_const:\n",
    "        #X = sm.add_constant(X)\n",
    "        #model = sm.OLS(Y, X).fit()\n",
    "        #return model.params[1]\n",
    "    #model = sm.OLS(Y, X).fit()\n",
    "    #return model.params.values        \n",
    "        \n",
    "def allocate(context, data):    \n",
    "    # Set objective to match target weights as closely as possible, given constraints\n",
    "    objective = opt.TargetWeights(context.target_weights)\n",
    "    \n",
    "    # Define constraints\n",
    "    constraints = []\n",
    "    constraints.append(opt.MaxGrossExposure(MAX_GROSS_EXPOSURE))\n",
    "    \n",
    "    algo.order_optimal_portfolio(\n",
    "        objective=objective,\n",
    "        constraints=constraints,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
